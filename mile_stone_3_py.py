# -*- coding: utf-8 -*-
"""mile stone 3.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tWEAeHw3beMEQTU0BePkLcyaPifqEjEk
"""

# ================ INSTALL REQUIRED PACKAGES ================
!pip install -q duckduckgo-search wikipedia langchain huggingface_hub sentence-transformers gradio
!pip install -q beautifulsoup4 requests

# ================ IMPORTS ================
import requests
from bs4 import BeautifulSoup
import json
import time
from typing import Dict, List, Any
from datetime import datetime
import re
import warnings
warnings.filterwarnings('ignore')

# ================ 1. FREE SEARCH AGENT (No API Key) ================
class FreeSearcher:
    """Uses free search sources: DuckDuckGo, Wikipedia, and web scraping"""

    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

    def search_duckduckgo(self, query: str, max_results: int = 3) -> List[Dict]:
        """Search using DuckDuckGo (no API key needed)"""
        from duckduckgo_search import DDGS

        results = []
        try:
            with DDGS() as ddgs:
                for r in ddgs.text(query, max_results=max_results):
                    results.append({
                        'title': r.get('title', 'No title'),
                        'url': r.get('href', ''),
                        'snippet': r.get('body', '')[:200]
                    })
        except Exception as e:
            print(f"DuckDuckGo search error: {e}")
            results = []

        return results

    def search_wikipedia(self, query: str) -> Dict:
        """Search Wikipedia for information"""
        try:
            # Try to get Wikipedia page
            search_url = f"https://en.wikipedia.org/w/api.php"
            params = {
                'action': 'query',
                'format': 'json',
                'list': 'search',
                'srsearch': query,
                'utf8': 1,
                'srlimit': 1
            }

            response = requests.get(search_url, params=params, timeout=10)
            data = response.json()

            if data['query']['search']:
                page_title = data['query']['search'][0]['title']

                # Get page content
                content_params = {
                    'action': 'query',
                    'format': 'json',
                    'titles': page_title,
                    'prop': 'extracts',
                    'exintro': True,
                    'explaintext': True
                }

                content_response = requests.get(search_url, params=content_params, timeout=10)
                content_data = content_response.json()

                pages = content_data['query']['pages']
                page_id = list(pages.keys())[0]
                extract = pages[page_id].get('extract', 'No content found')

                return {
                    'title': page_title,
                    'content': extract[:500],
                    'url': f"https://en.wikipedia.org/wiki/{page_title.replace(' ', '_')}",
                    'source': 'wikipedia'
                }
        except Exception as e:
            print(f"Wikipedia search error: {e}")

        return {}

    def search_web(self, query: str, max_results: int = 2) -> List[Dict]:
        """Simple web search using requests"""
        results = []

        # Try multiple search approaches
        try:
            # Approach 1: DuckDuckGo
            ddg_results = self.search_duckduckgo(query, max_results)
            results.extend(ddg_results)

            # Approach 2: Wikipedia
            wiki_result = self.search_wikipedia(query)
            if wiki_result:
                results.append(wiki_result)

            # Approach 3: Simple Google-like search via requests
            if len(results) < max_results:
                try:
                    # Use a simple public API
                    search_query = query.replace(' ', '+')
                    url = f"https://api.duckduckgo.com/?q={search_query}&format=json&no_html=1&skip_disambig=1"

                    response = requests.get(url, headers=self.headers, timeout=10)
                    data = response.json()

                    if data.get('AbstractText'):
                        results.append({
                            'title': data.get('Heading', 'DuckDuckGo Instant Answer'),
                            'url': data.get('AbstractURL', ''),
                            'snippet': data.get('AbstractText', '')[:300],
                            'source': 'duckduckgo_api'
                        })

                    # Extract related topics
                    for topic in data.get('RelatedTopics', [])[:2]:
                        if 'Text' in topic:
                            results.append({
                                'title': topic.get('Name', 'Related Topic'),
                                'url': topic.get('FirstURL', ''),
                                'snippet': topic.get('Text', '')[:200],
                                'source': 'duckduckgo_related'
                            })
                except:
                    pass

        except Exception as e:
            print(f"Web search error: {e}")

        # Ensure we have results
        if not results:
            results = [{
                'title': 'No online results found',
                'url': '',
                'snippet': 'Try rephrasing your query or check your internet connection.',
                'source': 'fallback'
            }]

        return results[:max_results]

    def extract_content(self, url: str) -> str:
        """Extract readable content from a URL"""
        try:
            response = requests.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')

            # Remove scripts and styles
            for script in soup(["script", "style", "nav", "footer", "header"]):
                script.decompose()

            # Get text
            text = soup.get_text()

            # Clean up text
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text = ' '.join(chunk for chunk in chunks if chunk)

            return text[:1000]  # Return first 1000 chars

        except Exception as e:
            return f"Could not extract content: {str(e)}"

# ================ 2. LOCAL LLM AGENT (No API Key) ================
class LocalLLMAgent:
    """Uses local HuggingFace models or simple rule-based responses"""

    def __init__(self, use_local_model=False):
        self.use_local_model = use_local_model
        self.model = None
        self.tokenizer = None

        if use_local_model:
            self._load_local_model()

    def _load_local_model(self):
        """Load a small local model (optional)"""
        try:
            from transformers import pipeline
            self.generator = pipeline('text-generation',
                                     model='distilgpt2',
                                     max_length=200,
                                     truncation=True)
            print("Loaded local model: distilgpt2")
        except Exception as e:
            print(f"Could not load local model: {e}")
            self.generator = None

    def generate_response(self, prompt: str, context: str = "") -> str:
        """Generate a response using local model or rule-based approach"""

        # Rule-based responses for common queries
        common_responses = {
            "hello": "Hello! I'm your research assistant. How can I help you today?",
            "hi": "Hi there! What would you like to research?",
            "thank you": "You're welcome! Is there anything else you'd like to know?",
            "thanks": "You're welcome! Feel free to ask more questions.",
            "who are you": "I'm an AI research assistant that helps find and summarize information from various sources.",
            "what can you do": "I can help research topics, summarize information from the web, and answer questions based on available information."
        }

        prompt_lower = prompt.lower().strip()
        for key, response in common_responses.items():
            if key in prompt_lower:
                return response

        # If we have a local model, use it
        if self.use_local_model and self.generator:
            try:
                full_prompt = f"Context: {context}\n\nQuestion: {prompt}\n\nAnswer:"
                result = self.generator(full_prompt, max_length=300, do_sample=True)[0]
                return result['generated_text'].split("Answer:")[-1].strip()
            except:
                pass

        # Fallback: Use a template-based response
        return self._template_response(prompt, context)

    def _template_response(self, prompt: str, context: str) -> str:
        """Create a template-based response"""

        # Check for specific question types
        prompt_lower = prompt.lower()

        if any(word in prompt_lower for word in ["what is", "explain", "define"]):
            return f"Based on my research:\n\n{context if context else 'I found information about your topic. '}This appears to be the key information available."

        elif any(word in prompt_lower for word in ["how to", "steps", "guide"]):
            return f"Here's what I found about how to do this:\n\n{context if context else 'The process involves several steps. '}You might want to consult additional resources for detailed instructions."

        elif any(word in prompt_lower for word in ["why", "reason", "cause"]):
            return f"From the available information:\n\n{context if context else 'There are several factors to consider. '}The reasons appear to be as described above."

        elif any(word in prompt_lower for word in ["compare", "difference", "versus", "vs"]):
            return f"Comparison based on research:\n\n{context if context else 'Here are the key differences: '}Each has its own advantages and use cases."

        else:
            # Generic response
            return f"""Research Summary:

Based on available information about "{prompt}":

{context if context else 'I gathered information from various sources. '}

Key Points:
1. Multiple sources provide information on this topic
2. The information suggests various perspectives
3. Further research might provide more specific details

Note: This is a summary based on publicly available information. For authoritative information, consider consulting official sources or experts in the field."""

# ================ 3. RESEARCH PIPELINE ================
class ResearchAssistant:
    """Main research pipeline that coordinates everything"""

    def __init__(self):
        self.searcher = FreeSearcher()
        self.writer = LocalLLMAgent(use_local_model=False)  # Set to True if you want local model
        self.conversation_history = []

        # Cache for previously searched topics
        self.search_cache = {}

        print("âœ… Research Assistant initialized!")
        print("   Using free search sources (DuckDuckGo, Wikipedia)")
        print("   No API keys required!")

    def process_query(self, query: str) -> str:
        """Process a research query"""
        print(f"\nğŸ” Processing: '{query}'")

        # Add to history
        self.conversation_history.append({
            "role": "user",
            "content": query,
            "timestamp": datetime.now().isoformat()
        })

        # Check cache first
        cache_key = query.lower().strip()
        if cache_key in self.search_cache:
            print("   Using cached results...")
            search_results = self.search_cache[cache_key]
        else:
            # Step 1: Search for information
            print("   Searching the web...")
            search_results = self.searcher.search_web(query, max_results=3)
            self.search_cache[cache_key] = search_results

        # Step 2: Prepare context from search results
        context = self._prepare_context(search_results, query)

        # Step 3: Generate response
        print("   Generating response...")
        response = self.writer.generate_response(query, context)

        # Add to history
        self.conversation_history.append({
            "role": "assistant",
            "content": response,
            "timestamp": datetime.now().isoformat(),
            "sources": [r.get('title', 'Unknown') for r in search_results]
        })

        # Keep history manageable
        if len(self.conversation_history) > 20:
            self.conversation_history = self.conversation_history[-20:]

        print("   âœ… Done!")
        return response

    def _prepare_context(self, search_results: List[Dict], query: str) -> str:
        """Prepare context from search results"""
        if not search_results:
            return "No specific information found in search results."

        context = f"Search results for '{query}':\n\n"

        for i, result in enumerate(search_results, 1):
            context += f"{i}. {result.get('title', 'No title')}\n"
            context += f"   Source: {result.get('source', 'web')}\n"
            context += f"   Summary: {result.get('snippet', 'No summary available')}\n"

            # Try to get more content for the first result
            if i == 1 and result.get('url'):
                try:
                    more_content = self.searcher.extract_content(result['url'])
                    if len(more_content) > 50:
                        context += f"   Additional: {more_content[:300]}...\n"
                except:
                    pass

            context += "\n"

        return context

    def get_history(self) -> List[Dict]:
        """Get conversation history"""
        return self.conversation_history.copy()

    def clear_history(self):
        """Clear conversation history"""
        self.conversation_history = []
        self.search_cache = {}
        print("ğŸ—‘ï¸ History and cache cleared")

# ================ 4. TEST THE ASSISTANT ================
def test_assistant():
    """Test the research assistant"""
    print("ğŸ§ª Testing Research Assistant...")
    print("=" * 60)

    assistant = ResearchAssistant()

    # Test queries
    test_queries = [
        "What is artificial intelligence?",
        "Explain climate change",
        "How does the internet work?",
        "What are the benefits of exercise?"
    ]

    for query in test_queries[:2]:  # Test first 2 queries
        print(f"\nğŸ¤” User: {query}")
        response = assistant.process_query(query)
        print(f"\nğŸ¤– Assistant:\n{response[:300]}...")  # Show first 300 chars
        print("-" * 60)
        time.sleep(2)  # Be nice to servers

    return assistant

# Run test
print("ğŸš€ Starting Research Assistant...")
assistant = test_assistant()

# ================ 5. GRADIO INTERFACE ================
import gradio as gr

# Create interface
def gradio_chat_interface(message, history):
    """Gradio chat function"""
    if not message.strip():
        return "Please enter a question."

    # Get response from assistant
    response = assistant.process_query(message)

    return response

def clear_gradio_chat():
    """Clear chat in Gradio"""
    assistant.clear_history()
    return None, []

# Create the interface
with gr.Blocks(theme=gr.themes.Soft(), title="Free Research Assistant") as demo:
    gr.Markdown("""
    # ğŸ” FREE Research Assistant
    **No API keys required!** Uses DuckDuckGo, Wikipedia, and web search.

    *Ask me anything and I'll research it for you!*
    """)

    # Chat interface
    chatbot = gr.Chatbot(
        height=400,
        bubble_full_width=False,
        avatar_images=(None, "ğŸ¤–"),
        show_copy_button=True
    )

    # Input
    msg = gr.Textbox(
        placeholder="Type your question here...",
        label="Your Question",
        scale=4
    )

    # Buttons
    with gr.Row():
        submit_btn = gr.Button("Send", variant="primary", size="lg")
        clear_btn = gr.Button("Clear Chat", variant="secondary")

    # Examples
    examples = gr.Examples(
        examples=[
            "What is machine learning?",
            "Explain quantum computing",
            "Tell me about the solar system",
            "What are renewable energy sources?",
            "How does photosynthesis work?",
            "Who invented the telephone?",
            "What is blockchain technology?"
        ],
        inputs=msg,
        label="Try these examples:"
    )

    # Chat function
    def respond(message, chat_history):
        if not message.strip():
            return "", chat_history

        # Add user message
        chat_history.append((message, ""))

        # Get response
        response = assistant.process_query(message)

        # Update last message
        chat_history[-1] = (message, response)

        return "", chat_history

    # Connect components
    msg.submit(respond, [msg, chatbot], [msg, chatbot])
    submit_btn.click(respond, [msg, chatbot], [msg, chatbot])
    clear_btn.click(clear_gradio_chat, None, [msg, chatbot])

    # Info section
    gr.Markdown("""
    ### ğŸ“Š How it works:
    1. **Search**: Uses DuckDuckGo, Wikipedia, and web scraping
    2. **Process**: Extracts and summarizes information
    3. **Respond**: Provides a comprehensive answer

    ### âš ï¸ Notes:
    - Completely free, no API keys needed
    - May be slower than paid services
    - Information comes from public sources
    - Always verify critical information
    """)

# Launch the interface
print("\n" + "="*60)
print("ğŸš€ Launching FREE Research Assistant Interface...")
print("ğŸ‘‰ The interface will appear below")
print("ğŸ‘‰ If using Colab, click the public link when it appears")
print("="*60)

try:
    # Try to launch with public URL for Colab
    demo.launch(share=True, debug=False)
except:
    # Fallback to local only
    demo.launch(share=False, debug=False)

# ================ 6. ALTERNATIVE: SIMPLE TEXT INTERFACE ================
def simple_text_interface():
    """Simple text-based interface if Gradio fails"""
    print("\n" + "="*60)
    print("ğŸ“Ÿ Text-based Research Assistant")
    print("="*60)
    print("Commands:")
    print("  Type your question to research")
    print("  'history' - See conversation history")
    print("  'clear' - Clear history")
    print("  'quit' - Exit")
    print("="*60)

    assistant = ResearchAssistant()

    while True:
        try:
            user_input = input("\nYou: ").strip()

            if user_input.lower() == 'quit':
                print("Goodbye! ğŸ‘‹")
                break
            elif user_input.lower() == 'history':
                history = assistant.get_history()
                print("\nğŸ“œ Conversation History:")
                for i, msg in enumerate(history):
                    role = "You" if msg["role"] == "user" else "Assistant"
                    print(f"{i+1}. {role}: {msg['content'][:80]}...")
                continue
            elif user_input.lower() == 'clear':
                assistant.clear_history()
                print("History cleared.")
                continue
            elif not user_input:
                continue

            # Process query
            print("\nğŸ¤– Researching...")
            response = assistant.process_query(user_input)

            # Display response
            print("\n" + "ğŸ“„ Assistant Response " + "="*40)
            print(response)
            print("="*60)

        except KeyboardInterrupt:
            print("\n\nGoodbye! ğŸ‘‹")
            break
        except Exception as e:
            print(f"\nâŒ Error: {e}")

# Uncomment to use text interface
# print("\nğŸ“± Starting text interface...")
# simple_text_interface()

# ================ 7. BONUS: SAVE AND LOAD CONVERSATIONS ================
def save_conversation(assistant, filename="conversation.json"):
    """Save conversation to file"""
    try:
        with open(filename, 'w') as f:
            json.dump(assistant.get_history(), f, indent=2)
        print(f"ğŸ’¾ Conversation saved to {filename}")
    except Exception as e:
        print(f"âŒ Could not save conversation: {e}")

def load_conversation(filename="conversation.json"):
    """Load conversation from file"""
    try:
        with open(filename, 'r') as f:
            history = json.load(f)

        assistant = ResearchAssistant()
        assistant.conversation_history = history
        print(f"ğŸ“‚ Conversation loaded from {filename}")
        return assistant
    except:
        print(f"âŒ Could not load conversation from {filename}")
        return ResearchAssistant()

# Example usage:
# save_conversation(assistant)
# loaded_assistant = load_conversation()

print("\nâœ… Setup complete! Your free Research Assistant is ready to use!")
print("\nğŸ’¡ Tips:")
print("1. Ask specific questions for better results")
print("2. Use the examples to get started")
print("3. The assistant learns from previous questions in the session")